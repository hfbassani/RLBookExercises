{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"Copy of Ex_3.01.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"eDhozwnBmotU"},"source":["#### *Exercise 3.1*\n","\n","#### Devise three example tasks of your own that fit into the MDP framework, identifying for each its states, actions, and rewards. Make the three examples as different from each other as possible. The framework is abstract and flexible and can be applied in many different ways. Stretch its limits in some way in at least one of your examples."]},{"cell_type":"markdown","metadata":{"id":"Si9xVdDTmotc"},"source":["---\n","#### Resposta 1:\n","Um framework de uma MDP (Markov Decision Process) consiste em um conjunto de estados, ações e recompensas. Vamos considerar uma MDP finita, logo o conjunto de estados, ações e recompensas são também finitos. \n","\n","Exemplo 1: Considerando um reservatório de água, vamos supor que temos um agente cujo objetivo é encher o reservatório de água e evitar que ele transborde. Os estados são o nível do reservatório, as ações são abrir ou fechar o local por onde passa a água que enche o reservatório e a recompensa é fornecer água para as pessoas e evitar o desperdício por transbordamento.\n","\n","Exemplo 2: Seja um hospital com um certo número de leitos. Este hospital recebe uma quantidade aleatória de pacientes e precisa decidir quantos pode admitir. Vale mencionar também que uma quantidade de pacientes se recupera e assim novos leitos serão liberados. O hospital gostaria de maximizar a quantidade de pessoas recuperadas ao longo do tempo. Para este problema, tem-se que os estados são o número de leitos disponíveis, a ação é a quantidade de pacientes que ele pode aceitar (baseado na quantidade de leitos disponíveis) e a recompensa é a quantidade de pessoas recuperadas naquele dia, que pode ser vista como uma função do número de leitos ocupados antes da ação e do número de leitos requisitados. \n","\n","Exemplo 3: Vamos considerar um Quiz com N níveis. A dificuldade cresce a cada nível e caso o jogador desista, o jogo acaba e ele recebe a recompensa acumulada por vencer os níveis anteriores. Neste caso os níveis são os estados e as ações são responder ou desistir. Uma resposta correta permite ao jogador avançar de nível e disputar a recompensa do próximo nível. Podemos modelar este problema como um grafo, em que os estados são os nós, as recompensas são os pesos das arestas, sendo o grafo direcionado e as arestas apontando para o próximo estado ou para o estado de fim, caso o jogador desista ou erre a pergunta. As probabilidades podem ser imaginadas para que as chances de o jogador acertar e ir para o próximo nível vão diminuindo, digamos que a probabilidade de ir do estado 1 para o estado 2 seja de 80% e de que ele acerte a última pergunta seja de 1%. Consequentemente a probabilidade de ele errar é de 1 - p, p sendo a probabilidade dele acertar. Por último, caso desista, há uma probabilidade de 100% dele ir para o estado de fim de jogo e obter a recompensa acumulada até aquele nível.  "]}]}