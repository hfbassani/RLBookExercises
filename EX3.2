 No MDP o ambiente é representado por um estado em um momento discreto de tempo, 
 onde há interação do agente com o ambiente. O estado deve conter todas as 
 informações necessárias para que um agente possa se situar no mundo e escolher 
 da melhor forma seus passos futuros. Para cada estado, o agente seleciona uma 
 ação da lista, e cada ação mudará o ambiente para um novo estado, o que resultará 
 em uma recompensa numérica. De tal forma, MDP não é eficiente em cenários onde é 
 não é possível representar os dados de forma númerica ou quando esses dados são 
 de difícil compreensão. Também não é adequado quando há possibilidades infinitas, 
 informações incompletas ou indisponíveis, como no jogo de xadrez, já que existem 
 incontáveis jogadas com probabilidades indefinidas.