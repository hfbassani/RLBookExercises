{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Exercise 4.2*\n",
    "\n",
    "#### In Example 4.1, suppose a new state 15 is added to the gridworld just below state 13, and its actions, left, up, right, and down, take the agent to states 12, 13, 14, and 15, respectively. Assume that the transitions from the original states are unchanged. What, then, is v⇡(15) for the equiprobable random policy? Now suppose the dynamics of state 13 are also changed, such that action down from state 13 takes the agent to the new state 15. What is v⇡(15) for the equiprobable random policy in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Resposta 1:\n",
    "\n",
    "Note que a pergunta consiste em dois cenários, ou subperguntas. Uma referente a um cenário em que as transições dos outros estados não mudam, e outra referente ao cenário em que uma transição do estado 13 muda. Denotarei esses dois cenários por A e B\n",
    "\n",
    "##### Cenário A:\n",
    "\n",
    "A valoração $V_\\pi$ não se altera para nenhum estado até o 14 porque eles não \"enxergam\" o estado 15. Mais formalmente, p(s', r | s, a) é nulo sempre que s' é o estado 15. Assim, é visível que os outros estados permanecem com o mesmo valor\n",
    "\n",
    "Quanto à valoração do estado 15, é suficiente notar que ele tem o mesmo comportamento do estado 13. Ou seja, a transição _left_ leva a um estado de valor -22, a transição _right_ leva a um de valor -14 e a transição _up_ leva a um de valor -20. \n",
    "\n",
    "As transições do estado 13 e 15 são as mesmas, com a sutil diferença da transição _up_ do estado 13. Ela leva ao estado 9, enquanto a transição _up_ do estado 15 leva ao estado 13. Porém, como o estado 13 e o estado 9 têm o mesmo valor, essa diferença na transição não impacta o valor do estado 15. Isso é suficiente para que saibamos que o valor do estado 15 é, também, -20.\n",
    "\n",
    "Caso alguém insista em olhar os cálculos, basta resolver a equação:\n",
    "$V_{15} = \\frac{1}{4}(-1-22) + \\frac{1}{4}(-1-20) + \\frac{1}{4}(-1-14) +  \\frac{1}{4}(-1-V_15)$\n",
    "<br>\n",
    "A qual resulta no valor esperado, -20. \n",
    "\n",
    "Algumas observações sobre a equação:\n",
    "<ul>\n",
    "<li>$\\frac{1}{4}$ é referente à probabilidade igual de cada transição.\n",
    "<li>-1 é a recompensa de cada transição\n",
    "<li>Demais valores são o valor de cada estado\n",
    "<li>$\\gamma$ é desconsiderado, visto que o livro descreve a tarefa como \"episódica e sem desconto\"\n",
    "</ul>\n",
    "\n",
    "##### Cenário B:\n",
    "\n",
    "Este cenário é melhor compreendido com base no cenário A. No cenário A, a transição _down_ a partir do estado 13 levava ao próprio estado 13. Agora, no cenário B, ela leva ao estado 15. Porém, os estados 15 e 13 têm o mesmo valor. Assim, o valor do estado 13 também não deve se alterar nesse novo cenário.\n",
    "\n",
    "Não apresento equações neste caso por entender que um tratamento rigoroso seria melhor resolvido numericamente, através do algoritmo apresentado nessa mesma seção do livro. Penso isso porque qualquer mudança no valor do estado 15 causaria uma mudança no valor do estado 13, que causaria um mudança de volta no estado 15, etc., dificultando uma soluação analítica.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
