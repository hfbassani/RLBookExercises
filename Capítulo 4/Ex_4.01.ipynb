{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ex4_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gExfhortJQgW"
      },
      "source": [
        "# Disciplina: Aprendizagem por Reforço\n",
        "**Aluno:** Julio Cezar Soares Silva\n",
        "\n",
        "**Professor:** Hansenclever Bassani \n",
        "\n",
        "**Exercício 4.1**\n",
        "In Example 4.1, if \\pi is the equiprobable random policy, what is $q_{\\pi}(11, down)$?\n",
        "What is $q_{\\pi}(7, down)$?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVUnvvJ3WSaC"
      },
      "source": [
        "Temos que $q(s,a)$ é dada por:\n",
        "\n",
        "$q(s,a)_\\pi = \\sum_{s',r}p(s',r|s,a)[r + \\gamma V_\\pi(s')]$\n",
        "\n",
        "Quando o retorno e o próximo estado são determinísticos, temos:\n",
        "\n",
        "$q(s,a)_\\pi = r(s,a,s') + \\gamma V_\\pi(s')$\n",
        "\n",
        "Portanto, observando função-valor estimada na Figura 4.1, temos:\n",
        "\n",
        "$q_\\pi(11,down) = r(11,down,terminal) + \\gamma V_\\pi(terminal) = -1 + 0 = -1$\n",
        "\n",
        "$q_\\pi(7,down) = r(7,down,11) + \\gamma V_\\pi(11)  = -1 - 14 = -15$"
      ]
    }
  ]
}