{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"Ex_1.03.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"XaNczAUigJQ8"},"source":["#### *Exercise 1.3*\n","\n","#### Greedy Play Suppose the reinforcement learning player was greedy, that is, it always played the move that brought it to the position that it rated the best. Might it learn to play better, or worse, than a nongreedy player? What problems might occur?"]},{"cell_type":"markdown","metadata":{"id":"0CEBBr4PgJRJ"},"source":["---\n","#### Resposta 1:\n","Uma vez que o jogador sempre opte pelo estado de maior probabilidade (greedy player), este será pior do que um jogador que explora outras jogadas (nongreedy player). Isso se dá porque o greedy player perde a possibilidade de descobrir novas jogadas que poderiam até ser melhor do que a jogada considerada mais valorizada atualmente. O ponto em questão é saber o quanto se deve explorar, se o jogador faz N jogadas, quantas dessas jogadas poderiam ter o intuito de explorar e quantas seguiriam o modelo greedy? Uma possibilidade é testar e verificar isso experimentalmente. Porém, independentemente da porcentagem de jogadas nongreedy (considerando uma porcentagem de até 10%), o jogador deve melhorar ou no mínimo permanecer na mesma condição, mas não piorar."]}]}