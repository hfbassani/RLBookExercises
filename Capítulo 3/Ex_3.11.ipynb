{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gExfhortJQgW"
      },
      "source": [
        "# Disciplina: Aprendizagem por Reforço\n",
        "**Aluno:** Julio Cezar Soares Silva\n",
        "\n",
        "**Professor:** Hansenclever Bassani \n",
        "\n",
        "**Exercício 3.11**\n",
        "If the current state is $S_t$, and actions are selected according to stochastic\n",
        "policy $\\pi$, then what is the expectation of $R_{t+1}$ in terms of $\\pi$  and the four-argument function p (3.2)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bh_jHld2szpF"
      },
      "source": [
        "Dado um estado $S_t = s$ e $A_t = a$, temos:\n",
        "\n",
        "$\n",
        "(eq. 1): E[R_{t+1}|S_t = s, A_t = a] = \\sum_{s'}\\sum_{r}r*p(s',r|s,a) \n",
        "$\n",
        "\n",
        "\n",
        "Percebe-se que com a política $\\pi$, cada ação terá uma probabilidade $\\pi(a|s)$ de ocorrer. Portanto, tem-se agora:\n",
        "\n",
        "$\n",
        "(eq. 2): E[R_{t+1}|S_t = s] = \\sum_{a}\\pi(a|s)*E[R_{t+1}|S_t = s, A_t = a]\n",
        "$\n",
        "\n",
        "Substituindo-se eq. 1 na eq. 2:\n",
        "\n",
        "$\n",
        "(eq. 2): E[R_{t+1}|S_t = s] = \\sum_{a}\\pi(a|s)*\\big(\\sum_{s'}\\sum_{r}r*p(s',r|s,a)\\big)\n",
        "$"
      ]
    }
  ]
}