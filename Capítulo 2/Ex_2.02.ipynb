{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"Ex_2.02.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"mDGoXAxDiECm"},"source":["#### *Exercise 2.2*\n","\n","#### Bandit example Consider a k-armed bandit problem with k = 4 actions, denoted 1, 2, 3, and 4. Consider applying to this problem a bandit algorithm using \"-greedy action selection, sample-average action-value estimates, and initial estimates of Q1(a) = 0, for all a. Suppose the initial sequence of actions and rewards is A1 = 1, R1 = −1, A2 = 2, R2 = 1, A3 = 2, R3 = −2, A4 = 2, R4 = 2, A5 = 3, R5 = 0. On some of these time steps the \" case may have occurred, causing an action to be selected at random. On which time steps did this definitely occur? On which time steps could this possibly have occurred?"]},{"cell_type":"markdown","metadata":{"id":"mxd-6zWgiECv"},"source":["---\n","#### Resposta 1:\n","Para responder a esta questão vamos fazer uso das equações (2.1) e (2.2). Levando em conta a equação (2.1), a condição inicial de Q<sub>1</sub>(a) = 0 para todas as ações e a dada sequência de ações e recompensas, fez-se uma tabela:\n","<pre>\n","t  | Q(a<sub>1</sub>) | Q(a<sub>2</sub>) | Q(a<sub>3</sub>) | Q(a<sub>4</sub>)  | A(t) \n","1  |   0   |   0   |   0   |   0   |  1 \n","2  |  -1   |   0   |   0   |   0   |  2 \n","3  |  -1   |   1   |   0   |   0   |  2 \n","4  |  -1   | -1/2  |   0   |   0   |  2 \n","5  |  -1   |  1/3  |   0   |   0   |  3 \n","6  |  -1   |  1/3  |   0   |   0   |  \n","\n","</pre>\n","\n","Os valores foram obtidos da seguinte forma:\n","\n","Q<sub>2</sub>(a<sub>1</sub>) = R<sub>1</sub>*1/1 = 1\n","\n","Q<sub>3</sub>(a<sub>2</sub>) = (R<sub>1</sub>* 0+R<sub>2</sub>*1)/1 = 1\n","\n","Q<sub>4</sub>(a<sub>2</sub>) = (R<sub>1</sub>* 0 + R<sub>2</sub>* 1 + R<sub>3</sub>*1)/2 = -1/2\n","\n","Q<sub>5</sub>(a<sub>2</sub>) = (R<sub>1</sub>* 0 + R<sub>2</sub>* 1 + R<sub>3</sub>* 1 + R<sub>4</sub>* 1)/3 = 1/3\n","\n","Q<sub>6</sub>(a<sub>3</sub>) = R<sub>5</sub>/1 = 0\n","\n","Analisando cada time step, tem-se:\n","\n","Em t = 1 todos os valores de Q são iguais a zero, logo a ação é escolhida aleatoriamente. Como não há uma ação com um valor de Q maior do que as outras, a decisão pode ser tomada levando em conta o caso &epsilon; ou 1 - &epsilon;.\n","\n","Para t = 2 existem 3 ações empatadas e novamente não se sabe se o critério usado foi o &epsilon; ou o 1 - &epsilon;. Note que em 1 - &epsilon; os empates são decididos de forma arbitrária.\n","\n","No time step t = 3 a ação 2 tem um valor maior do que as outras e é escolhida, logo, tem-se um caso 1 - &epsilon; (greedy play).\n","\n","Já em t = 4 a ação 2 é escolhida novamente, mas agora ela tem o menor valor de Q, logo pode-se afirmar que ela foi escolhida com base em &epsilon;.\n","\n","No caso de t = 5 a ação 3 é tomada, mesmo com a ação 2 sendo a ação ótima, logo, tem-se novamente um caso de &epsilon;.\n","\n","Em resumo, t = 1 e t = 2 são casos em que o case &epsilon; pode ter acontecido e t = 4 e t = 5 são time steps onde definitivamente ocorreram casos &epsilon;."]}]}