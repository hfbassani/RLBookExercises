{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ex1.3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hou5ZT1QcYmk"
      },
      "source": [
        "# Disciplina: Aprendizagem por Reforço\n",
        "**Aluno:** Julio Cezar Soares Silva\n",
        "\n",
        "**Professor:** Hansenclever Bassani \n",
        "\n",
        "**Exercício 1.3**\n",
        "Suppose the reinforcement learning player was greedy, that is,it always played the move that brought it to the position \n",
        "that it rated the best. Might it learn to play better, or worse, than a nongreedy player? What problems might occur?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhUYzeHhcUDe"
      },
      "source": [
        "O agente ganancioso ficará preso em uma determinada política visto que nunca irá explorar o ganho/perda de outros \n",
        "estados para recalibrar seu conhecimento atual. Já o agente mais aleatório, não vai utilizar o seu conhecimento para \n",
        "gerar mais ganhos, apenas irá continuar agindo de maneira aleatória. Portanto, o jogador aleatório é mais propenso a perder de um jogador ganancioso, se o ganancioso estiver preso a uma política boa. Portanto, é por isto que deve-se encontrar formas de equilibrar \n",
        "atualização do conhecimento(exploration) e uso do conhecimento adquirido (exploitation) para desenvolver agentes mais competitivos.\n",
        "\n"
      ]
    }
  ]
}